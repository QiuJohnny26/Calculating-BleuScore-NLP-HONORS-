# Calculating-BleuScore-NLP-HONORS-

<------------------------------------------------------------------------------------------->

Little Background (Referenced from https://machinelearningmastery.com/calculate-bleu-score-for-text-python/):
BLEU, or the Bilingual Evaluation Understudy, is a score for comparing a candidate translation of text to one or more reference translations.
Although developed for translation, it can be used to evaluate text generated for a suite of natural language processing tasks.
The Bilingual Evaluation Understudy Score, or BLEU for short, is a metric for evaluating a generated sentence to a reference sentence.
A perfect match results in a score of 1.0, whereas a perfect mismatch results in a score of 0.0.The score was developed for evaluating 
the predictions made by automatic machine translation systems.

<------------------------------------------------------------------------------------------->

  NLP Honors course where i created my own implementation of Bleu Score with C++, and with the reference sentences , I used an accurate metric 
to  compute the value compared to the candidate sentence. I also included my own implementation of the distance calculator between the 
sentences to further analyze the comparison .

How to Run it
1.Download the zip file
2.Edit The text file to configure the candidate sentence you want to test with reference sentences
3.Run it

